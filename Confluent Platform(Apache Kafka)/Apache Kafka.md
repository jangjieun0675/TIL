# Kafka 개요

## 1. Kafka란 무엇인가?
- 아파치 소프트웨어 재단에서 개발한 **분산 이벤트 스트리밍 플랫폼**  
- 데이터를 **빠르게 수집**하고 **처리**하는 데 특화된 시스템  
- 주로 **대용량 데이터 처리**, **실시간 분석**, **마이크로서비스 통신** 등에 사용  
- 데이터 흐름을 최적화하고, **실시간 데이터 기반 의사결정**을 강화할 수 있다  

---

## 2. Kafka의 핵심기능과 특징

### ● 이벤트 스트리밍(Event Streaming)
- **이벤트 스트림**은 결제, 주문, 데이터베이스 변경 등과 같은 **실시간 이벤트**를 의미  
- Kafka는 이러한 이벤트를 **밀리초 단위**로 생성하고 수집하며, 다양한 시스템과 공유할 수 있다  
- 여러 서비스가 생성한 데이터를 **빠르고 실시간으로 전달**하는 역할을 한다  

### ● 필요한 만큼 보관 및 기록 재처리(데이터 보존)
- Kafka는 수집된 데이터를 **필요한 기간 동안 보관**할 수 있다  
- 데이터를 단순히 저장하는 것을 넘어서, **과거 데이터를 재생**해 특정 시점의 이벤트를 다시 처리할 수 있다  
- **데이터 손실 없이 재처리**가 가능해 유용하다  

### ● 지속적인 실시간 처리
- Kafka를 사용하면 **실시간 이벤트**에 즉각적으로 대응하는 애플리케이션을 개발할 수 있다  
- 확장 가능한 **가볍고 탄력적인 애플리케이션**을 구축할 수 있어 **마이크로서비스 환경**에 적합  
- 이벤트 발생과 동시에 처리할 수 있어 **실시간 작업**을 지원  

### ● 데이터 스트림과 테이블의 통합 및 분석
- Kafka는 **데이터 스트림과 정적 테이블 데이터**를 실시간으로 결합하여 처리할 수 있다  
- **24시간 중단 없이** 처리와 분석이 가능하며, 실시간 의사 결정을 지원  
- 이를 통해 **데이터 기반 의사 결정**이 신속하게 이루어질 수 있다  

### ● 데이터의 유연한 이동과 연결(어디서나 사용 가능)
- Kafka는 기업 내부와 외부의 모든 시스템을 연결하는 **데이터 이동 플랫폼**으로 활용된다  
- 데이터 센터, 시스템, **클라우드 간 데이터 이동**을 원활하게 지원  
- Kafka는 동일한 기술로 **클라우드 환경과 온프레미스(On-premise) 환경**에서 모두 신뢰성 있게 사용될 수 있다  
  - **온프레미스(On-premise) 환경**: 서버를 직접 설치·운영하는 방식으로, 원격 클라우드 운영과 대비되는 개념  

### ● 초대규모 처리 능력
- Kafka는 **매우 큰 규모의 데이터를 안정적으로 처리**할 수 있다  
- 일일 **수조 개의 이벤트**를 처리할 수 있으며, 기업의 프로덕션 환경에서도 **안정적인 성능**을 제공한다  

---

## 3. Kafka의 주요 사용 사례
- **실시간 금융거래 처리**: 결제나 주문 데이터를 실시간으로 처리해 고객에게 즉각적인 피드백 제공  
- **로그 및 모니터링 데이터 수집**: 시스템 로그를 실시간으로 수집하고 분석해 문제를 신속하게 감지  
- **IoT(사물인터넷) 데이터 처리**: 센서와 기기에서 발생하는 데이터를 실시간으로 수집하고 분석  
- **마이크로서비스 통신**: 여러 마이크로서비스 간 **비동기 메시지 전송**을 통해 효율적인 통신 구현  

---

## 4. Kafka의 아키텍처 구성요소
Kafka는 **스토리지 계층**과 **컴퓨팅 계층**으로 나누어져 실시간 데이터 처리를 지원한다.

### ① 스토리지 계층(Storage Layer)
- **역할**: 데이터를 효율적으로 저장하고 보관  
- **확장성**: Kafka는 **분산 시스템**으로, 데이터 양이 증가할 때 **서버(브로커)**를 추가해 확장 가능  
- **데이터 보관 방식**: 데이터는 **토픽(Topic)** 단위로 저장되며, 각 토픽은 **파티션(Partition)**으로 나눠져 성능을 높인다  
  - 예: 결제 시스템이 Kafka를 사용해 거래 기록을 저장할 때 데이터가 많아지면, 서버를 추가해 처리 가능  

### ② 컴퓨팅 계층(Computing Layer)
Kafka는 **데이터 처리**와 **애플리케이션 간 통신**을 위한 4가지 구성 요소로 이루어져 있다.  

#### ⓐ Producer(생산자)
- **데이터 생성 후 Kafka로 전송**  
- 여러 서비스가 생성한 데이터를 Kafka **토픽으로 전송**  
  - 예: 쇼핑몰 결제 완료 시, 결제 정보를 Kafka로 전달  

#### ⓑ Consumer(소비자)
- **Kafka에 저장된 데이터를 사용**  
- 특정 토픽의 데이터를 **구독(subscribe)**하여 실시간으로 처리  
  - 예: 결제 발생 시 소비자 애플리케이션이 데이터를 받아 고객에게 알림 전송  

#### ⓒ Stream API(스트림 API)
- **실시간 데이터 처리 및 분석** 도구  
- 여러 이벤트를 **조합하거나 변환**하여 처리 가능  
  - 예: 결제 데이터와 주문 데이터를 결합해 실시간 매출 분석 수행  

#### ⓓ Connector API(커넥터 API)
- Kafka를 **외부 시스템과 연결**해 데이터 송수신 가능  
- **데이터베이스, 클라우드 서비스** 등과 연동에 사용  
  - 예: 결제 데이터가 데이터베이스에 자동 업데이트될 때 Kafka 활용  

---

## 5. ksqlDB(SQL을 활용한 스트리밍 데이터베이스)
- **역할**: Kafka Streams 기반의 **스트리밍 데이터베이스**로, 복잡한 코딩 없이 **SQL과 유사한 구문**으로 실시간 데이터를 처리합니다.  
- **기능**: SELECT, WHERE, JOIN과 같은 **SQL 구문**을 사용해 데이터를 조회하고 처리할 수 있습니다.  

**예시**:  
최근 1시간 동안 발생한 주문 수를 실시간으로 조회하는 ksqlDB 쿼리:  
```sql
SELECT COUNT(*) 
FROM orders_stream 
WHERE order_time > NOW() - INTERVAL '1' HOUR;
```

---

## 6. Kafka의 데이터 처리 흐름
1. **Producer**가 결제와 같은 이벤트를 생성해 Kafka로 전송  
2. Kafka의 **스토리지 계층**이 데이터를 **토픽과 파티션**으로 나눠 저장  
3. **Consumer**가 특정 토픽을 구독하고 데이터를 실시간으로 가져옴  
4. 필요한 경우 **Stream API**를 사용해 여러 데이터를 조합하여 처리  
5. **Connector API**로 **데이터베이스나 클라우드**와 데이터를 주고받음  

---

## 7. Kafka 아키텍처의 장점
- **확장성**: 서버(브로커) 추가로 데이터 양이 많아져도 손쉽게 확장 가능  
- **고성능**: 데이터를 파티션으로 나눠 여러 서버에서 동시에 처리해 성능 향상  
- **내구성**: Kafka에 저장된 데이터는 필요 시 **재생 및 재처리** 가능  
- **다양한 연동성**: **Connector API**로 여러 시스템과 손쉽게 통합 가능  
